
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.48">
    
    
      
        <title>CUDA C/C++ Programming Notes - Andy's Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cuda-cc-programming-notes" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Andy&#39;s Notes" class="md-header__button md-logo" aria-label="Andy's Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Andy's Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CUDA C/C++ Programming Notes
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="orange"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Andy&#39;s Notes" class="md-nav__button md-logo" aria-label="Andy's Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Andy's Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Artificial Intelligence
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Artificial Intelligence
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Hardware
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Hardware
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../hardware.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hardware
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../memory.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Memory Hierarchy Design
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../parallelism.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel Computing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cpu-vs-gpu-matrix.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cache-Aware Matrix Multiplication & GPU Performance Analysis
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Software
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../cuda.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA C/C++
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Convolutional Neural Networks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Convolutional Neural Networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../neural.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CNN Concepts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../1d_cnn.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1-D CNN Examples
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../jetson.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Nvidia's Jetson Nano
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Automotive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Automotive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Automotive/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Automotive/pages/architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Electrical/Electronic Architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Automotive/pages/sensorsSignals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    External Sensors and Signals
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Protocols
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Protocols
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Protocols/pages/can/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CAN
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Hardware
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Hardware
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Automotive/pages/pdm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Power Distribution Module
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Cyber Security
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Cyber Security
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Cybersecurity/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Digital Systems Design
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Digital Systems Design
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DSD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DSD/verilog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Verilog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DSD/logicDesign/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logic Design
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DSD/simulations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Simulations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../DSD/applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Examples
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Electronics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Electronics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../electronics/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../electronics/pages/equipment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measuring Equipment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../electronics/pages/opamp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Operational Amplifiers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../electronics/pages/adc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Analog to Digital Converter
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Physics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Physics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Physics/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
        
          
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Quanta and Fields
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            Quanta and Fields
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Physics/pages/waveFunction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Wave Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Physics/pages/measurement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measurement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Physics/pages/entanglement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entanglement
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Physics/pages/fields/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fields
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Protocols and Interfaces
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Protocols and Interfaces
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Protocols/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Protocols/pages/can/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CAN
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Senior Design
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Senior Design
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../senior_design/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Signals
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Signals
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Signals/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Signals/pages/introDsp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Digital Signal Processing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Signals/pages/spectrum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FCC Electromagnetic Spectrum
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Software
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Software/pages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Software/pages/developmentProcess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Development Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Software/pages/c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    C Programming Language
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#heterogeneous-computing" class="md-nav__link">
    <span class="md-ellipsis">
      Heterogeneous Computing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Heterogeneous Computing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#host-and-device-relationship" class="md-nav__link">
    <span class="md-ellipsis">
      Host and Device relationship
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#simple-processing-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Simple Processing Flow
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hello-world" class="md-nav__link">
    <span class="md-ellipsis">
      Hello World
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hello World">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#host-cpu-example" class="md-nav__link">
    <span class="md-ellipsis">
      Host (CPU) Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-device-gpu-example" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA Device (GPU) Example
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#addition-on-the-device" class="md-nav__link">
    <span class="md-ellipsis">
      Addition on the Device
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vector-addition-on-the-device" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Addition on the Device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Vector Addition on the Device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#device-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Device Kernel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#host-code-example" class="md-nav__link">
    <span class="md-ellipsis">
      Host Code Example
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Indexing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Indexing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-indexing-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Indexing Concepts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-example" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-dimensional-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Dimensional Indexing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#handling-arbitrary-vector-sizes" class="md-nav__link">
    <span class="md-ellipsis">
      Handling Arbitrary Vector Sizes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shared-memory-1d-stencil-and-__syncthreads" class="md-nav__link">
    <span class="md-ellipsis">
      Shared Memory, 1D Stencil, and __syncthreads()
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Shared Memory, 1D Stencil, and __syncthreads()">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_1" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#shared-memory-basics" class="md-nav__link">
    <span class="md-ellipsis">
      Shared Memory Basics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-1d-stencil-operation" class="md-nav__link">
    <span class="md-ellipsis">
      The 1D Stencil Operation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The 1D Stencil Operation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-1d-stencil-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Example: 1D Stencil Kernel
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-the-kernel-works" class="md-nav__link">
    <span class="md-ellipsis">
      How the Kernel Works
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-role-of-__syncthreads" class="md-nav__link">
    <span class="md-ellipsis">
      The Role of __syncthreads()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#managing-the-device" class="md-nav__link">
    <span class="md-ellipsis">
      Managing the Device
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Managing the Device">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_2" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#querying-and-selecting-devices" class="md-nav__link">
    <span class="md-ellipsis">
      Querying and Selecting Devices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-device-management" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Device Management
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#synchronization-and-error-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Synchronization and Error Handling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="cuda-cc-programming-notes">CUDA C/C++ Programming Notes</h1>
<h2 id="overview">Overview</h2>
<p><strong>What is CUDA?</strong><br />
CUDA is a parallel computing architecture developed by NVIDIA that allows developers to leverage GPU acceleration for general-purpose computing, not just graphics.</p>
<p><strong>Key points:</strong></p>
<ul>
<li>Exposes GPU parallelism for general-purpose computing while retaining high performance.</li>
<li>Based on industry-standard C/C++ with a small set of extensions, like <code>Malloc() -&gt; cudaMalloc()</code> and <code>Memcpy() -&gt; cudaMemcpy()</code></li>
<li>Provides straightforward APIs to manage devices, memory, and kernels.</li>
<li>Enables writing and launching CUDA kernels, managing GPU memory, and handling synchronization between the CPU (host) and GPU (device).</li>
</ul>
<p><strong>Difference between host and device:</strong></p>
<ul>
<li><strong>Host:</strong> CPU</li>
<li><strong>Device:</strong> GPU</li>
</ul>
<p><strong>Using <code>__global__</code> to declare a function as device code:</strong></p>
<ul>
<li>Executes on the device (GPU)</li>
<li>Called from the host (CPU)</li>
</ul>
<hr />
<h2 id="heterogeneous-computing">Heterogeneous Computing</h2>
<h3 id="host-and-device-relationship">Host and Device relationship</h3>
<ul>
<li><strong>Host:</strong> The CPU and its associated memory; executes serial portions of code.</li>
<li><strong>Device:</strong> The GPU and its dedicated memory; executes parallel portions of code efficiently.</li>
</ul>
<p><img alt="" src="../../assets/hetero.png" /></p>
<h3 id="simple-processing-flow">Simple Processing Flow</h3>
<p><img alt="" src="../../assets/cuda_gif0.gif" /></p>
<hr />
<h2 id="hello-world">Hello World</h2>
<h3 id="host-cpu-example">Host (CPU) Example</h3>
<p>A simple C program running entirely on the CPU:</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello World!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li>Standard C code executed by the CPU.</li>
<li>Compiled using a standard C compiler like <code>gcc</code>.</li>
<li>Outputs <code>Hello World!</code> directly.</li>
</ul>
<h3 id="cuda-device-gpu-example">CUDA Device (GPU) Example</h3>
<p>A basic CUDA C program that launches a kernel (device function) on the GPU:</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// Device kernel (does nothing here)</span>
<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mykernel</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Launch kernel on the GPU</span>
<span class="w">    </span><span class="n">mykernel</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Host code continues</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Hello World!</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><code>__global__</code> keyword specifies a CUDA kernel (runs on GPU, called from CPU).</li>
<li>Triple angle brackets <code>&lt;&lt;&lt; &gt;&gt;&gt;</code> indicate kernel launch parameters (1 block, 1 thread).</li>
<li>Requires NVIDIA's CUDA compiler (<code>nvcc</code>) to compile.</li>
<li>Kernel launch does nothing visible here; real work happens inside device code.</li>
<li>Still prints <code>Hello World!</code> from the CPU (host).</li>
</ul>
<hr />
<h2 id="addition-on-the-device">Addition on the Device</h2>
<p>A basic CUDA C program performing addition on the GPU:</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;stdio.h&gt;</span>

<span class="c1">// Device kernel for addition</span>
<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="o">*</span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_c</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Allocate memory on GPU</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_c</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// Copy values to GPU</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch kernel on GPU</span>
<span class="w">    </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="n">d_c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Copy result back to CPU</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">d_c</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Free GPU memory</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_a</span><span class="p">);</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_b</span><span class="p">);</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_c</span><span class="p">);</span>

<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;Sum: %d</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><code>__global__</code> defines a kernel function to execute on the GPU.</li>
<li>Uses CUDA-specific functions for memory management (<code>cudaMalloc</code>, <code>cudaMemcpy</code>, <code>cudaFree</code>).</li>
<li>Kernel launch syntax (<code>&lt;&lt;&lt;1, 1&gt;&gt;&gt;</code>) specifies execution configuration: 1 block, 1 thread.</li>
<li>Data must be explicitly transferred between host (CPU) and device (GPU).</li>
<li>Compiled with NVIDIA's CUDA compiler (<code>nvcc</code>).</li>
</ul>
<hr />
<h2 id="vector-addition-on-the-device">Vector Addition on the Device</h2>
<h3 id="device-kernel">Device Kernel</h3>
<div class="codehilite"><pre><span></span><code><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">c</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li>Each block handles one element of the addition.</li>
<li>Blocks run in parallel on the GPU.</li>
</ul>
<p><strong>Example of Parallel Execution:</strong></p>
<ul>
<li><strong>Block 0:</strong> <code>c[0] = a[0] + b[0];</code></li>
<li><strong>Block 1:</strong> <code>c[1] = a[1] + b[1];</code></li>
<li><strong>Block 2:</strong> <code>c[2] = a[2] + b[2];</code></li>
<li><strong>Block 3:</strong> <code>c[3] = a[3] + b[3];</code></li>
</ul>
<h3 id="host-code-example">Host Code Example</h3>
<div class="codehilite"><pre><span></span><code><span class="cp">#define N 512</span>

<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="p">;</span><span class="w"> </span><span class="c1">// host copies of a, b, c</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_c</span><span class="p">;</span><span class="w"> </span><span class="c1">// device copies of a, b, c</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Allocate space for device copies</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_c</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Allocate space for host copies and setup input values</span>
<span class="w">    </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span><span class="w"> </span><span class="n">random_ints</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">    </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span><span class="w"> </span><span class="n">random_ints</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
<span class="w">    </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Copy inputs to device</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Launch add() kernel on GPU with N blocks</span>
<span class="w">    </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="n">d_c</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Copy result back to host</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">d_c</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// Cleanup</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span><span class="w"> </span><span class="n">free</span><span class="p">(</span><span class="n">b</span><span class="p">);</span><span class="w"> </span><span class="n">free</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_a</span><span class="p">);</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_b</span><span class="p">);</span><span class="w"> </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">d_c</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li>Allocates and manages memory explicitly.</li>
<li>Each GPU block computes one addition in parallel.</li>
<li>Data transferred between host and GPU explicitly.</li>
</ul>
<hr />
<p>Below is a new section on <strong>Indexing</strong> that integrates the concepts covered on pages 3748:</p>
<hr />
<h2 id="indexing">Indexing</h2>
<p>Efficient indexing is key to mapping threads to data elements in CUDA. In CUDAs parallel programming model, each thread in a grid must be assigned a unique portion of the data. This section outlines the common strategies and formulas used for indexing in CUDA kernels.</p>
<h3 id="basic-indexing-concepts">Basic Indexing Concepts</h3>
<p>CUDA organizes threads into blocks, and blocks form a grid. Each thread within a block is uniquely identified by <code>threadIdx</code>, while each block in the grid is identified by <code>blockIdx</code>.</p>
<p><img alt="" src="../../assets/thread0.png" /></p>
<p><strong>Built-in Variables:</strong>  </p>
<ul>
<li><code>threadIdx.x</code>: The threads index within its block (in the x-dimension).  </li>
<li><code>blockIdx.x</code>: The blocks index within the grid (in the x-dimension).  </li>
<li><code>blockDim.x</code>: The number of threads in a block (in the x-dimension). In the example above <code>blockDim.x = 8</code></li>
</ul>
<p><strong>The Indexing Formula:</strong> When processing one-dimensional arrays, the unique global index for each thread is calculated using:</p>
<div class="codehilite"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</code></pre></div>

<h3 id="practical-example">Practical Example</h3>
<p>Consider a kernel launch where each block contains 8 threads. For a thread with:</p>
<ul>
<li><code>threadIdx.x = 5</code>  </li>
<li><code>blockIdx.x = 2</code>  </li>
<li><code>M = blockDim.x = 8</code></li>
</ul>
<p><img alt="" src="../../assets/index.png" /></p>
<p>This means that the thread processes the 22nd element (using zero-based indexing) of the array.</p>
<h3 id="multi-dimensional-indexing">Multi-Dimensional Indexing</h3>
<p>For higher-dimensional data, CUDA supports three-dimensional configurations:</p>
<p><strong>2D Indexing:</strong><br />
When working with images or matrices, you may compute a unique index using both x and y dimensions:</p>
<div class="codehilite"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">;</span><span class="w"> </span><span class="c1">// &#39;width&#39; is the number of columns</span>
</code></pre></div>

<p><strong>3D Indexing:</strong>  </p>
<p>For volume data, a similar approach extends to three dimensions using <code>threadIdx.z</code>, <code>blockIdx.z</code>, and <code>blockDim.z</code>.</p>
<h3 id="handling-arbitrary-vector-sizes">Handling Arbitrary Vector Sizes</h3>
<p>Often, the total number of data elements is not an exact multiple of the block size. To safely process all elements without accessing out-of-bound memory, include a bounds check in your kernel:</p>
<div class="codehilite"><pre><span></span><code><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">index</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<ul>
<li><strong>Kernel Launch:</strong><br />
  The number of blocks is computed to cover all elements:</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="w"> </span><span class="n">d_b</span><span class="p">,</span><span class="w"> </span><span class="n">d_c</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</code></pre></div>

<p>Below is a new section that covers shared memory, 1D stencils, and the use of __syncthreads() in CUDA. You can integrate this section into your notes as follows:</p>
<hr />
<h2 id="shared-memory-1d-stencil-and-__syncthreads">Shared Memory, 1D Stencil, and __syncthreads()</h2>
<h3 id="overview_1">Overview</h3>
<p>CUDA provides a fast, user-managed on-chip memory called <strong>shared memory</strong> that all threads within a block can access. This section demonstrates how to leverage shared memory for a 1D stencil operation and explains the role of the synchronization primitive <code>__syncthreads()</code>.</p>
<h3 id="shared-memory-basics">Shared Memory Basics</h3>
<ul>
<li>
<p><strong>Definition:</strong><br />
  Shared memory is declared with the <code>__shared__</code> keyword. It is a limited, high-speed memory region accessible by all threads within the same block.</p>
</li>
<li>
<p><strong>Purpose:</strong><br />
  It is used to cache data from global memory to reduce redundant memory accesses, thereby improving performanceespecially in operations that reuse data, such as stencil computations.</p>
</li>
</ul>
<h3 id="the-1d-stencil-operation">The 1D Stencil Operation</h3>
<p>A stencil operation processes each element of an input array by combining it with its neighboring elements. For example, with a <strong>radius</strong> of 3, each output element is computed by summing 7 consecutive elements from the input array.</p>
<p><img alt="" src="../../assets/stencil.png" /></p>
<h4 id="example-1d-stencil-kernel">Example: 1D Stencil Kernel</h4>
<div class="codehilite"><pre><span></span><code><span class="cp">#define BLOCK_SIZE 16</span>
<span class="cp">#define RADIUS 3</span>

<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">stencil_1d</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">out</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// Declare shared memory with additional space for halo elements</span>
<span class="w">    </span><span class="n">__shared__</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">temp</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Calculate global and local indices</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">gindex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">lindex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Load the main data element into shared memory</span>
<span class="w">    </span><span class="n">temp</span><span class="p">[</span><span class="n">lindex</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">gindex</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// Load halo elements (neighbors) needed for the stencil</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">temp</span><span class="p">[</span><span class="n">lindex</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">gindex</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">];</span>
<span class="w">        </span><span class="n">temp</span><span class="p">[</span><span class="n">lindex</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">gindex</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Synchronize to ensure all shared memory loads are complete</span>
<span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// Apply the stencil: sum the element and its neighbors</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">RADIUS</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">RADIUS</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">result</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">temp</span><span class="p">[</span><span class="n">lindex</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// Write the result back to global memory</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">gindex</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="how-the-kernel-works">How the Kernel Works</h3>
<ul>
<li><strong>Data Loading:</strong><br />
  Each thread loads one data element from global memory into a designated location in the shared memory array (<code>temp</code>). Threads with an index less than <code>RADIUS</code> also load extra "halo" elements from the boundaries. These halo elements provide the necessary neighboring data for the stencil computation.</li>
</ul>
<p><img alt="" src="../../assets/halo.png" /></p>
<ul>
<li>
<p><strong>Synchronization with __syncthreads():</strong><br />
  The call to <code>__syncthreads()</code> is essential because it ensures that all threads have finished loading their data into shared memory before any thread begins processing. This barrier prevents data races, ensuring that every thread sees the correct, complete data.</p>
</li>
<li>
<p><strong>Stencil Computation:</strong><br />
  After synchronization, each thread applies the stencil by summing the element at its local index (<code>lindex</code>) along with its surrounding elements within the radius. The result is then written back to global memory.</p>
</li>
</ul>
<h3 id="the-role-of-__syncthreads">The Role of __syncthreads()</h3>
<ul>
<li>
<p><strong>Barrier for Threads:</strong><br />
<code>__syncthreads()</code> acts as a barrier where all threads in a block must reach before any can proceed. This is crucial when threads depend on data loaded by other threads.</p>
</li>
<li>
<p><strong>Preventing Data Hazards:</strong><br />
  It prevents race conditions by ensuring that shared memory writes are completed before any thread begins reading the data for computation.</p>
</li>
<li>
<p><strong>Uniform Execution Requirement:</strong><br />
  All threads within a block must execute the same <code>__syncthreads()</code> call (i.e., it should not be placed inside a condition that may evaluate differently across threads) to avoid deadlocks.</p>
</li>
</ul>
<h3 id="practical-considerations">Practical Considerations</h3>
<ul>
<li>
<p><strong>Handling Boundaries:</strong><br />
  When the total number of elements does not neatly divide into blocks, additional boundary checks may be necessary to prevent out-of-bounds memory access.</p>
</li>
<li>
<p><strong>Performance Optimization:</strong><br />
  Efficient use of shared memory can significantly reduce global memory accesses, especially in stencil operations where the same data may be reused by multiple threads.</p>
</li>
</ul>
<hr />
<p>Below is a new section that covers managing the device, based on the content from the provided CUDA slides (ppt pages 60+):</p>
<hr />
<h2 id="managing-the-device">Managing the Device</h2>
<h3 id="overview_2">Overview</h3>
<p>CUDA applications must manage GPU devices effectively to ensure optimal performance, especially in systems with multiple GPUs. This section describes how to query available devices, select the appropriate device for execution, retrieve device properties, and perform advanced operations like peer-to-peer memory copies.</p>
<h3 id="querying-and-selecting-devices">Querying and Selecting Devices</h3>
<ul>
<li>
<p><strong>Querying Devices:</strong><br />
  Use <code>cudaGetDeviceCount(int *count)</code> to determine the number of CUDA-capable GPUs in your system. This helps in dynamically adjusting your application to the available hardware.</p>
</li>
<li>
<p><strong>Selecting a Device:</strong><br />
  Once you know the available devices, use <code>cudaSetDevice(int device)</code> to select the GPU on which your kernels will run. This is essential in multi-GPU systems where you might want to distribute workloads.</p>
</li>
<li>
<p><strong>Getting the Current Device:</strong><br />
  Use <code>cudaGetDevice(int *device)</code> to find out which device is currently active.</p>
</li>
<li>
<p><strong>Retrieving Device Properties:</strong><br />
  To get detailed information about a GPUsuch as its memory size, number of registers, clock rate, and compute capabilityuse:</p>
</li>
</ul>
<p><code>c
  cudaDeviceProp prop;
  cudaGetDeviceProperties(&amp;prop, device);</code></p>
<p>This information can be used to optimize your code for the specific hardware.</p>
<h3 id="advanced-device-management">Advanced Device Management</h3>
<ul>
<li>
<p><strong>Multi-threading and Device Sharing:</strong><br />
  Multiple host threads can share a single GPU, and a single thread can manage multiple GPUs by switching between them using successive calls to <code>cudaSetDevice</code>.</p>
</li>
<li>
<p><strong>Peer-to-Peer Memory Copies:</strong><br />
  CUDA supports direct memory copies between GPUs with <code>cudaMemcpy(...)</code>, provided that the operating system and the GPUs support peer-to-peer transfers. This can further enhance performance by bypassing the host memory for inter-device communication.</p>
</li>
</ul>
<h3 id="synchronization-and-error-handling">Synchronization and Error Handling</h3>
<ul>
<li>
<p><strong>Synchronizing Host and Device:</strong><br />
  Kernel launches are asynchronous by default. Use <code>cudaDeviceSynchronize()</code> to block the host until all preceding CUDA calls have completed. This is crucial before copying results back to the host or when precise timing is required.</p>
</li>
<li>
<p><strong>Error Reporting:</strong><br />
  Every CUDA API call returns an error code. After making an API call, check for errors using:</p>
</li>
</ul>
<p><code>c
  cudaError_t err = cudaGetLastError();
  if (err != cudaSuccess) {
      printf("CUDA Error: %s\n", cudaGetErrorString(err));
  }</code></p>
<p>This practice helps in diagnosing issues related to device management and kernel execution.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Managing the device in CUDA involves more than simply launching kernels. By querying device capabilities, selecting the appropriate GPU, and handling synchronization and errors properly, you ensure that your application fully leverages the available hardware resources for optimal performance.</p>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>